package main

// Write a Go program that implements a simple concurrent web crawler.
// The crawler should start from a given URL and visit links on that page, continuing to a specified depth.
// Use Go routines to crawl multiple pages concurrently, and ensure that each page is only visited once.

// Hint: Use a map to track visited URLs and channels to coordinate the crawling process. Use sync.Mutex to manage access to shared resources.

func main() {

}
